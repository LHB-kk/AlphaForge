{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "instruments = 'csi300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from alphagen.data.expression import *\n",
    "from alphagen.models.alpha_pool import AlphaPool\n",
    "from alphagen.utils.correlation import batch_pearsonr, batch_spearmanr\n",
    "from alphagen_generic.features import *\n",
    "from gan.utils.data import get_data_by_year\n",
    "\n",
    "\n",
    "def pred_pool(capacity,data,cache):\n",
    "    from alphagen_qlib.calculator import QLibStockDataCalculator\n",
    "    pool = AlphaPool(capacity=capacity,\n",
    "                    stock_data=data,\n",
    "                    target=target,\n",
    "                    ic_lower_bound=None)\n",
    "    exprs = []\n",
    "    for key in dict(Counter(cache).most_common(capacity)):\n",
    "        exprs.append(eval(key))\n",
    "    pool.force_load_exprs(exprs)\n",
    "    pool._optimize(alpha=5e-3, lr=5e-4, n_iter=2000)\n",
    "\n",
    "    exprs = pool.exprs[:pool.size]\n",
    "    weights = pool.weights[:pool.size]\n",
    "    calculator_test = QLibStockDataCalculator(data, target)\n",
    "    ensemble_value = calculator_test.make_ensemble_alpha(exprs, weights)\n",
    "    return ensemble_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_gp/csi300_2021_day_0\n",
      "Data not exist, load from qlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4818:MainThread](2025-12-12 11:21:51,933) INFO - qlib.Initialization - [config.py:452] - default_conf: client.\n",
      "[4818:MainThread](2025-12-12 11:21:52,443) INFO - qlib.Initialization - [__init__.py:82] - qlib successfully initialized based on client settings.\n",
      "[4818:MainThread](2025-12-12 11:21:52,445) INFO - qlib.Initialization - [__init__.py:84] - data_path={'day': PosixPath('/root/autodl-tmp/qlib_data/cn_data_202512')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_start_time: 2010-08-04 00:00:00\n",
      "real_end_time: 2022-02-21 00:00:00\n",
      "real_start_time: 2021-08-05 00:00:00\n",
      "real_end_time: 2023-02-20 00:00:00\n",
      "real_start_time: 2019-08-06 00:00:00\n",
      "real_end_time: 2023-02-20 00:00:00\n",
      "real_start_time: 2022-08-05 00:00:00\n",
      "real_end_time: 2024-02-20 00:00:00\n",
      "real_start_time: 2020-08-06 00:00:00\n",
      "real_end_time: 2024-02-20 00:00:00\n",
      "real_start_time: 2010-08-04 00:00:00\n",
      "real_end_time: 2024-02-20 00:00:00\n",
      "out_gp/csi300_2021_day_0\n",
      "out_gp/csi300_2021_day_0\n",
      "out_gp/csi300_2021_day_0\n",
      "out_gp/csi300_2022_day_0\n",
      "Data not exist, load from qlib\n",
      "real_start_time: 2010-08-04 00:00:00\n",
      "real_end_time: 2023-02-20 00:00:00\n",
      "real_start_time: 2022-08-05 00:00:00\n",
      "real_end_time: 2024-02-20 00:00:00\n",
      "real_start_time: 2020-08-06 00:00:00\n",
      "real_end_time: 2024-02-20 00:00:00\n",
      "real_start_time: 2023-08-04 00:00:00\n",
      "real_end_time: 2025-02-20 00:00:00\n",
      "real_start_time: 2021-08-05 00:00:00\n",
      "real_end_time: 2025-02-20 00:00:00\n",
      "real_start_time: 2010-08-04 00:00:00\n",
      "real_end_time: 2025-02-20 00:00:00\n",
      "out_gp/csi300_2022_day_0\n",
      "out_gp/csi300_2022_day_0\n",
      "out_gp/csi300_2022_day_0\n",
      "out_gp/csi300_2023_day_0\n",
      "Data not exist, load from qlib\n",
      "real_start_time: 2010-08-04 00:00:00\n",
      "real_end_time: 2024-02-20 00:00:00\n",
      "real_start_time: 2023-08-04 00:00:00\n",
      "real_end_time: 2025-02-20 00:00:00\n",
      "real_start_time: 2021-08-05 00:00:00\n",
      "real_end_time: 2025-02-20 00:00:00\n",
      "real_start_time: 2024-08-05 00:00:00\n",
      "real_end_time: 2025-12-09 00:00:00\n",
      "real_start_time: 2022-08-05 00:00:00\n",
      "real_end_time: 2025-12-09 00:00:00\n",
      "real_start_time: 2010-08-04 00:00:00\n",
      "real_end_time: 2025-12-09 00:00:00\n",
      "out_gp/csi300_2023_day_0\n",
      "out_gp/csi300_2023_day_0\n",
      "out_gp/csi300_2023_day_0\n"
     ]
    }
   ],
   "source": [
    "# for seed in range(5):\n",
    "for seed in range(1):\n",
    "    for train_end in range(2021,2024):\n",
    "        for num in [1,10,20,50]:\n",
    "            save_dir = f'out_gp/{instruments}_{train_end}_day_{seed}' \n",
    "            print(save_dir)\n",
    "            \n",
    "            returned = get_data_by_year(\n",
    "                train_start = 2011,train_end=train_end,valid_year=train_end+1,test_year =train_end+2,\n",
    "                instruments=instruments, target=target,freq='day',\n",
    "            )\n",
    "            data_all,data,data_valid,data_valid_withhead,data_test,data_test_withhead,name = returned\n",
    "\n",
    "            cache = json.load(open(f'{save_dir}/40.json'))['cache']\n",
    "\n",
    "            features = ['open_', 'close', 'high', 'low', 'volume', 'vwap']\n",
    "            constants = [f'Constant({v})' for v in [-30., -10., -5., -2., -1., -0.5, -0.01, 0.01, 0.5, 1., 2., 5., 10., 30.]]\n",
    "            terminals = features + constants\n",
    "\n",
    "            pred = pred_pool(num,data_all,cache=cache)\n",
    "            pred = pred[-data_test.n_days:]\n",
    "            torch.save(pred.detach().cpu(),f\"{save_dir}/pred_{num}.pt\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and combine result to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'seed': 0, 'num': 1, 'ic': 0.004189000930637121, 'ric': 0.053484391421079636, 'icir': 0.04278258347401724, 'ricir': 0.34536648024986094}]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for num in [1]:\n",
    "    # for seed in range(5):\n",
    "    for seed in range(1):\n",
    "        cur_seed_ic = []\n",
    "        cur_seed_ric = []\n",
    "        for train_end in range(2021,2024):\n",
    "                save_dir = f'out_gp/{instruments}_{train_end}_day_{seed}' \n",
    "\n",
    "                returned = get_data_by_year(\n",
    "                    train_start = 2011,train_end=train_end,valid_year=train_end+1, test_year=train_end+2,\n",
    "                    instruments=instruments, target=target,freq='day',\n",
    "                )\n",
    "                data_all,data,data_valid,data_valid_withhead,data_test,data_test_withhead,name = returned\n",
    "\n",
    "                pred = torch.load(f\"{save_dir}/pred_{num}.pt\").to('cuda:0')\n",
    "                \n",
    "                # tgt = target.evaluate(data_test)\n",
    "                tgt = target.evaluate(data_all)[-data_test.n_days:,:]\n",
    "\n",
    "                ic_s = torch.nan_to_num(batch_pearsonr(pred,tgt),nan=0)\n",
    "                rank_ic_s = torch.nan_to_num(batch_spearmanr(pred,tgt),nan=0)\n",
    "\n",
    "                cur_seed_ic.append(ic_s)\n",
    "                cur_seed_ric.append(rank_ic_s)\n",
    "        \n",
    "        ic = torch.cat(cur_seed_ic)\n",
    "        rank_ic = torch.cat(cur_seed_ric)\n",
    "\n",
    "        ic_mean = ic.mean().item()\n",
    "        rank_ic_mean = rank_ic.mean().item()\n",
    "        ic_std = ic.std().item()\n",
    "        rank_ic_std = rank_ic.std().item()\n",
    "        tmp = dict(\n",
    "            seed = seed,\n",
    "            num = num,\n",
    "            ic = ic_mean,\n",
    "            ric = rank_ic_mean,\n",
    "            icir = ic_mean/ic_std,\n",
    "            ricir = rank_ic_mean/rank_ic_std,\n",
    "        )\n",
    "        result.append(tmp)\n",
    "import pandas as pd\n",
    "print(pd.DataFrame(result).groupby(['num','seed']).mean().groupby('num').agg(['mean','std']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
